args.epoch = 100, args.lr=0.001, args.batch_size=20, args.num_workers=4
args.train_file=../../dataset/train.csv, args.train_dir=../../dataset/train_images/, args.test_dir=../../dataset/test_images/
args.augment_data=false, args.leslie=false, args.lr_min=1e-05, args.lr_max=1.0
epochs 1/100 
learning rate :  0.002131522905486037
train loss : 4.6110
maskloss : 1.7407
regrloss : 2.2760
offsetloss : 0.5944
precision : 0.0200
epochs 2/100 
learning rate :  0.002524650099055205
train loss : 4.0725
maskloss : 1.4204
regrloss : 2.0698
offsetloss : 0.5823
precision : 0.0000
epochs 3/100 
learning rate :  0.003175072811480502
train loss : 4.0231
maskloss : 1.3815
regrloss : 2.0621
offsetloss : 0.5795
precision : 0.0000
epochs 4/100 
learning rate :  0.004075662252350919
train loss : 3.8737
maskloss : 1.2724
regrloss : 2.0390
offsetloss : 0.5622
precision : 0.0000
epochs 5/100 
learning rate :  0.0052165477433403495
train loss : 3.5625
maskloss : 1.0998
regrloss : 1.9194
offsetloss : 0.5434
precision : 0.0000
epochs 6/100 
learning rate :  0.006585224903231962
train loss : 3.2388
maskloss : 0.9608
regrloss : 1.7652
offsetloss : 0.5127
precision : 0.0000
epochs 7/100 
learning rate :  0.00816669269896398
train loss : 3.0347
maskloss : 0.8915
regrloss : 1.6584
offsetloss : 0.4848
precision : 0.0000
epochs 8/100 
learning rate :  0.009943617860584147
train loss : 2.9402
maskloss : 0.8623
regrloss : 1.6057
offsetloss : 0.4721
precision : 0.0000
epochs 9/100 
learning rate :  0.01189652485808515
train loss : 2.8364
maskloss : 0.8351
regrloss : 1.5428
offsetloss : 0.4585
precision : 0.0000
epochs 10/100 
learning rate :  0.014004009357929052
train loss : 2.7631
maskloss : 0.8182
regrloss : 1.4928
offsetloss : 0.4522
precision : 0.0000
epochs 11/100 
learning rate :  0.016242972819725338
train loss : 2.7137
maskloss : 0.8052
regrloss : 1.4619
offsetloss : 0.4465
precision : 11.4554
epochs 12/100 
learning rate :  0.018588875661826286
train loss : 2.6411
maskloss : 0.7889
regrloss : 1.4143
offsetloss : 0.4379
precision : 0.0000
epochs 13/100 
learning rate :  0.021016006221083475
train loss : 2.5734
maskloss : 0.7753
regrloss : 1.3677
offsetloss : 0.4304
precision : 0.0000
epochs 14/100 
learning rate :  0.023497762558901285
train loss : 2.5269
maskloss : 0.7677
regrloss : 1.3325
offsetloss : 0.4267
precision : 0.0000
epochs 15/100 
learning rate :  0.02600694402492486
train loss : 2.4623
maskloss : 0.7537
regrloss : 1.2891
offsetloss : 0.4195
precision : 0.0000
epochs 16/100 
learning rate :  0.02851604938275395
train loss : 2.4108
maskloss : 0.7434
regrloss : 1.2540
offsetloss : 0.4135
precision : 0.0000
epochs 17/100 
learning rate :  0.030997578230152534
train loss : 2.3627
maskloss : 0.7343
regrloss : 1.2218
offsetloss : 0.4066
precision : 0.0000
epochs 18/100 
learning rate :  0.033424332410115824
train loss : 2.3190
maskloss : 0.7249
regrloss : 1.1912
offsetloss : 0.4029
precision : 0.0000
epochs 19/100 
learning rate :  0.0357697141092564
train loss : 2.2870
maskloss : 0.7158
regrloss : 1.1686
offsetloss : 0.4027
precision : 0.0000
epochs 20/100 
learning rate :  0.03800801737627885
train loss : 2.2397
maskloss : 0.7031
regrloss : 1.1405
offsetloss : 0.3961
precision : 0.0000
epochs 21/100 
learning rate :  0.04011470986543006
train loss : 2.1943
maskloss : 0.6911
regrloss : 1.1113
offsetloss : 0.3920
precision : 34.4435
epochs 22/100 
learning rate :  0.04206670171694846
train loss : 2.1468
maskloss : 0.6740
regrloss : 1.0850
offsetloss : 0.3877
precision : 0.0000
epochs 23/100 
learning rate :  0.043842598627517625
train loss : 2.0865
maskloss : 0.6523
regrloss : 1.0530
offsetloss : 0.3811
precision : 0.0000
epochs 24/100 
learning rate :  0.04542293633701077
train loss : 2.0746
maskloss : 0.6416
regrloss : 1.0535
offsetloss : 0.3795
precision : 0.0000
epochs 25/100 
learning rate :  0.046790393961494404
train loss : 1.9727
maskloss : 0.6035
regrloss : 1.0022
offsetloss : 0.3670
precision : 0.0000
epochs 26/100 
learning rate :  0.047929983834310116
train loss : 1.9065
maskloss : 0.5716
regrloss : 0.9751
offsetloss : 0.3597
precision : 0.0000
epochs 27/100 
learning rate :  0.04882921577452996
train loss : 1.8217
maskloss : 0.5435
regrloss : 0.9275
offsetloss : 0.3507
precision : 0.0000
epochs 28/100 
learning rate :  0.049478233982363645
train loss : 1.7456
maskloss : 0.5189
regrloss : 0.8854
offsetloss : 0.3414
precision : 0.0000
epochs 29/100 
learning rate :  0.04986992506111054
train loss : 1.6833
maskloss : 0.4977
regrloss : 0.8526
offsetloss : 0.3330
precision : 0.0000
epochs 30/100 
learning rate :  0.04999999598170982
train loss : 1.6252
maskloss : 0.4793
regrloss : 0.8199
offsetloss : 0.3261
precision : 0.0000
epochs 31/100 
learning rate :  0.04986702113537846
train loss : 1.5456
maskloss : 0.4559
regrloss : 0.7718
offsetloss : 0.3178
precision : 51.5231
epochs 32/100 
learning rate :  0.049472457958628625
train loss : 1.4874
maskloss : 0.4394
regrloss : 0.7404
offsetloss : 0.3076
precision : 0.0000
epochs 33/100 
learning rate :  0.04882063095941064
train loss : 1.4311
maskloss : 0.4215
regrloss : 0.7088
offsetloss : 0.3007
precision : 0.0000
epochs 34/100 
learning rate :  0.04791868431945879
train loss : 1.3780
maskloss : 0.4046
regrloss : 0.6775
offsetloss : 0.2959
precision : 0.0000
epochs 35/100 
learning rate :  0.04677650359232974
train loss : 1.3260
maskloss : 0.3897
regrloss : 0.6482
offsetloss : 0.2880
precision : 0.0000
epochs 36/100 
learning rate :  0.04540660735534198
train loss : 1.2912
maskloss : 0.3779
regrloss : 0.6294
offsetloss : 0.2839
precision : 0.0000
epochs 37/100 
learning rate :  0.04382401000293745
train loss : 1.2545
maskloss : 0.3640
regrloss : 0.6131
offsetloss : 0.2774
precision : 0.0000
epochs 38/100 
learning rate :  0.04204605718528304
train loss : 1.2135
maskloss : 0.3511
regrloss : 0.5876
offsetloss : 0.2749
precision : 0.0000
epochs 39/100 
learning rate :  0.040092235695745
train loss : 1.1630
maskloss : 0.3358
regrloss : 0.5591
offsetloss : 0.2681
precision : 0.0000
epochs 40/100 
learning rate :  0.03798395989091542
train loss : 1.1384
maskloss : 0.3252
regrloss : 0.5484
offsetloss : 0.2648
precision : 0.0000
epochs 41/100 
learning rate :  0.035744336984079056
train loss : 1.0850
maskloss : 0.3098
regrloss : 0.5175
offsetloss : 0.2577
precision : 53.5283
epochs 42/100 
learning rate :  0.03339791378456094
train loss : 1.0613
maskloss : 0.3020
regrloss : 0.5043
offsetloss : 0.2550
precision : 0.0000
epochs 43/100 
learning rate :  0.030970407658752752
train loss : 1.0337
maskloss : 0.2899
regrloss : 0.4926
offsetloss : 0.2512
precision : 0.0000
epochs 44/100 
learning rate :  0.028488424661550465
train loss : 0.9808
maskloss : 0.2755
regrloss : 0.4595
offsetloss : 0.2458
precision : 0.0000
epochs 45/100 
learning rate :  0.025979167927550673
train loss : 0.9546
maskloss : 0.2623
regrloss : 0.4523
offsetloss : 0.2400
precision : 0.0000
epochs 46/100 
learning rate :  0.023470139518108855
train loss : 0.9060
maskloss : 0.2473
regrloss : 0.4245
offsetloss : 0.2341
precision : 0.0000
epochs 47/100 
learning rate :  0.020988838992088088
train loss : 0.8987
maskloss : 0.2429
regrloss : 0.4229
offsetloss : 0.2328
precision : 0.0000
epochs 48/100 
learning rate :  0.018562462004035572
train loss : 0.8676
maskloss : 0.2278
regrloss : 0.4110
offsetloss : 0.2287
precision : 0.0000
epochs 49/100 
learning rate :  0.016217602233224063
train loss : 0.8243
maskloss : 0.2121
regrloss : 0.3901
offsetloss : 0.2221
precision : 0.0000
epochs 50/100 
learning rate :  0.013979959910488095
train loss : 0.7870
maskloss : 0.1990
regrloss : 0.3703
offsetloss : 0.2177
precision : 0.0000
epochs 51/100 
learning rate :  0.011874060137471394
train loss : 0.7693
maskloss : 0.1865
regrloss : 0.3690
offsetloss : 0.2138
precision : 56.4894
epochs 52/100 
learning rate :  0.009922984085574767
train loss : 0.7370
maskloss : 0.1748
regrloss : 0.3520
offsetloss : 0.2102
precision : 0.0000
epochs 53/100 
learning rate :  0.00814811602072901
train loss : 0.6974
maskloss : 0.1590
regrloss : 0.3351
offsetloss : 0.2033
precision : 0.0000
epochs 54/100 
learning rate :  0.006568908926662712
train loss : 0.6679
maskloss : 0.1478
regrloss : 0.3211
offsetloss : 0.1991
precision : 0.0000
epochs 55/100 
learning rate :  0.0052026712954905095
train loss : 0.6446
maskloss : 0.1371
regrloss : 0.3118
offsetloss : 0.1957
precision : 0.0000
epochs 56/100 
learning rate :  0.004064377422448747
train loss : 0.6220
maskloss : 0.1261
regrloss : 0.3039
offsetloss : 0.1920
precision : 0.0000
epochs 57/100 
learning rate :  0.003166503283994042
train loss : 0.6063
maskloss : 0.1197
regrloss : 0.2975
offsetloss : 0.1890
precision : 0.0000
epochs 58/100 
learning rate :  0.002518889798080597
train loss : 0.5919
maskloss : 0.1124
regrloss : 0.2927
offsetloss : 0.1868
precision : 0.0000
epochs 59/100 
learning rate :  0.0021286349653166746
train loss : 0.5726
maskloss : 0.1049
regrloss : 0.2835
offsetloss : 0.1842
precision : 0.0000
epochs 60/100 
learning rate :  0.0019999996235657014
train loss : 0.5635
maskloss : 0.1008
regrloss : 0.2802
offsetloss : 0.1825
precision : 0.0000
epochs 61/100 
learning rate :  0.001996850052995107
train loss : 0.5616
maskloss : 0.0991
regrloss : 0.2802
offsetloss : 0.1823
precision : 54.0101
epochs 62/100 
learning rate :  0.001987556883266271
train loss : 0.5535
maskloss : 0.0952
regrloss : 0.2773
offsetloss : 0.1810
precision : 0.0000
epochs 63/100 
learning rate :  0.0019721773940447945
train loss : 0.5521
maskloss : 0.0928
regrloss : 0.2792
offsetloss : 0.1801
precision : 0.0000
epochs 64/100 
learning rate :  0.0019508063788215336
train loss : 0.5443
maskloss : 0.0899
regrloss : 0.2751
offsetloss : 0.1793
precision : 0.0000
epochs 65/100 
learning rate :  0.0019235755606405384
train loss : 0.5399
maskloss : 0.0882
regrloss : 0.2728
offsetloss : 0.1789
precision : 0.0000
epochs 66/100 
learning rate :  0.0018906527802068599
train loss : 0.5361
maskloss : 0.0864
regrloss : 0.2717
offsetloss : 0.1781
precision : 0.0000
epochs 67/100 
learning rate :  0.001852240961378442
train loss : 0.5295
maskloss : 0.0833
regrloss : 0.2692
offsetloss : 0.1770
precision : 0.0000
epochs 68/100 
learning rate :  0.0018085768604184135
train loss : 0.5272
maskloss : 0.0812
regrloss : 0.2694
offsetloss : 0.1766
precision : 0.0000
epochs 69/100 
learning rate :  0.0017599296067169333
train loss : 0.5236
maskloss : 0.0799
regrloss : 0.2680
offsetloss : 0.1756
precision : 0.0000
epochs 70/100 
learning rate :  0.0017065990439770376
train loss : 0.5173
maskloss : 0.0768
regrloss : 0.2656
offsetloss : 0.1750
precision : 0.0000
epochs 71/100 
learning rate :  0.0016489138820888058
train loss : 0.5137
maskloss : 0.0747
regrloss : 0.2645
offsetloss : 0.1745
precision : 52.2668
epochs 72/100 
learning rate :  0.0015872296710830159
train loss : 0.5104
maskloss : 0.0730
regrloss : 0.2640
offsetloss : 0.1735
precision : 0.0000
epochs 73/100 
learning rate :  0.0015219266096520815
train loss : 0.5094
maskloss : 0.0718
regrloss : 0.2643
offsetloss : 0.1733
precision : 0.0000
epochs 74/100 
learning rate :  0.0014534072017457456
train loss : 0.5047
maskloss : 0.0696
regrloss : 0.2626
offsetloss : 0.1724
precision : 0.0000
epochs 75/100 
learning rate :  0.0013820937756854083
train loss : 0.4998
maskloss : 0.0684
regrloss : 0.2598
offsetloss : 0.1717
precision : 0.0000
epochs 76/100 
learning rate :  0.0013084258810883477
train loss : 0.4983
maskloss : 0.0665
regrloss : 0.2605
offsetloss : 0.1712
precision : 0.0000
epochs 77/100 
learning rate :  0.0012328575796462344
train loss : 0.4931
maskloss : 0.0649
regrloss : 0.2576
offsetloss : 0.1707
precision : 0.0000
epochs 78/100 
learning rate :  0.0011558546464565808
train loss : 0.4894
maskloss : 0.0635
regrloss : 0.2561
offsetloss : 0.1698
precision : 0.0000
epochs 79/100 
learning rate :  0.0010778916991570837
train loss : 0.4867
maskloss : 0.0623
regrloss : 0.2549
offsetloss : 0.1695
precision : 0.0000
epochs 80/100 
learning rate :  0.0009994492725578124
train loss : 0.4834
maskloss : 0.0605
regrloss : 0.2541
offsetloss : 0.1688
precision : 0.0000
epochs 81/100 
learning rate :  0.0009210108568021368
train loss : 0.4802
maskloss : 0.0597
regrloss : 0.2524
offsetloss : 0.1681
precision : 51.7459
epochs 82/100 
learning rate :  0.0008430599173120663
train loss : 0.4793
maskloss : 0.0590
regrloss : 0.2526
offsetloss : 0.1677
precision : 0.0000
epochs 83/100 
learning rate :  0.00076607691488597
train loss : 0.4742
maskloss : 0.0569
regrloss : 0.2503
offsetloss : 0.1670
precision : 0.0000
epochs 84/100 
learning rate :  0.000690536344315679
train loss : 0.4736
maskloss : 0.0564
regrloss : 0.2503
offsetloss : 0.1668
precision : 0.0000
epochs 85/100 
learning rate :  0.0006169038097758549
train loss : 0.4709
maskloss : 0.0552
regrloss : 0.2495
offsetloss : 0.1662
precision : 0.0000
epochs 86/100 
learning rate :  0.0005456331550118363
train loss : 0.4681
maskloss : 0.0543
regrloss : 0.2481
offsetloss : 0.1657
precision : 0.0000
epochs 87/100 
learning rate :  0.00047716366601442965
train loss : 0.4653
maskloss : 0.0535
regrloss : 0.2464
offsetloss : 0.1653
precision : 0.0000
epochs 88/100 
learning rate :  0.00041191736342331795
train loss : 0.4643
maskloss : 0.0531
regrloss : 0.2461
offsetloss : 0.1651
precision : 0.0000
epochs 89/100 
learning rate :  0.0003502964013477215
train loss : 0.4639
maskloss : 0.0529
regrloss : 0.2461
offsetloss : 0.1649
precision : 0.0000
epochs 90/100 
learning rate :  0.0002926805886370101
train loss : 0.4622
maskloss : 0.0522
regrloss : 0.2453
offsetloss : 0.1647
precision : 0.0000
epochs 91/100 
learning rate :  0.00023942504787924636
train loss : 0.4619
maskloss : 0.0523
regrloss : 0.2451
offsetloss : 0.1645
precision : 51.3848
epochs 92/100 
learning rate :  0.00019085802655672304
train loss : 0.4596
maskloss : 0.0512
regrloss : 0.2443
offsetloss : 0.1641
precision : 0.0000
epochs 93/100 
learning rate :  0.00014727887384972786
train loss : 0.4603
maskloss : 0.0520
regrloss : 0.2443
offsetloss : 0.1640
precision : 0.0000
epochs 94/100 
learning rate :  0.00010895619555876499
train loss : 0.4579
maskloss : 0.0505
regrloss : 0.2438
offsetloss : 0.1637
precision : 0.0000
epochs 95/100 
learning rate :  7.612619851761636e-05
train loss : 0.4585
maskloss : 0.0511
regrloss : 0.2437
offsetloss : 0.1637
precision : 0.0000
epochs 96/100 
learning rate :  4.899123470166551e-05
train loss : 0.4569
maskloss : 0.0504
regrloss : 0.2430
offsetloss : 0.1636
precision : 0.0000
epochs 97/100 
learning rate :  2.771855400506337e-05
train loss : 0.4558
maskloss : 0.0498
regrloss : 0.2426
offsetloss : 0.1634
precision : 0.0000
epochs 98/100 
learning rate :  1.2439273374158374e-05
train loss : 0.4589
maskloss : 0.0513
regrloss : 0.2437
offsetloss : 0.1639
precision : 0.0000
epochs 99/100 
learning rate :  3.2475686510689992e-06
train loss : 0.4564
maskloss : 0.0503
regrloss : 0.2426
offsetloss : 0.1634
precision : 0.0000
epochs 100/100 
learning rate :  2.0009410857915728e-07
train loss : 0.4562
maskloss : 0.0500
regrloss : 0.2428
offsetloss : 0.1634
precision : 0.0000
